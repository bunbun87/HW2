---
title: "Homework 2"
author: "Swetha Boaz & Aparajita Joshi"
date: "10/16/2020"
output: html_document
---

### Part I

1. We know that $\sum_{1=1}^{n} Y_i = nb_0 + b_1 \sum_{i=1}^{n}X_i$. We also know that $\hat{Y} = b_0 + b_1X$. Therefore, $\sum_{i=1}^{n}\hat{Y} = \sum_{i=1}^{n} (b_0 + b_1X)$. In order to simplify this second equation, we can take the $b_0$ out and put it in front of the summation symbol. Howver in doing this, we must pay attention to the fact that $b_0$ is added to the quantity $b_1X$ "n" times over the interval [i=1, n]. In order to maintain mathematical accuracy, we therefore rewrite the summation in the form $\sum_{i=1}^{n}\hat{Y} = nb_0 + \sum_{i=1}^{n}b_1X$. Let's suppose we used our new and improved equation to sovle for n = 10, $b_0$ would be added to $\sum_{i=1}^{n}b_1X$ 10 times, which is consistant with what would occur if we used $\sum_{i=1}^{n} (b_0 + b_1X$. We can still simplify this summation further by putting $b_1$ in front of the summation symbol. Note that $b_1$ is a coefficient of $X$ and therefore it is a constant. Using summation algebra, we rewrite our summation as $\sum_{i=1}^{n}\hat{Y} = nb_0 + b_1\sum_{i=1}^{n}X$. Comparing the two equations, $\sum_{1=1}^{n} Y_i = nb_0 + b_1 \sum_{i=1}^{n}X_i$ and $\sum_{i=1}^{n}\hat{Y} = nb_0 + b_1\sum_{i=1}^{n}X$, we see that they are indeed equal to each other. 

2. 


### Part II

1. From the simple regression model we know that $Y_i - B_0 -B_1X_i = \epsilon_{i}$. We know from homework #1 that the regression equation is as follows: Y = 3.913267X - 133.813276l 
```{r}
mydata = read.table("weight_full.txt", header=T)
attach(mydata)
h_bar = mean(mydata$height)
w_bar = mean(mydata$weight)
height = (mydata$height)
weight = (mydata$weight)
beta_hat_1 = sum((height-h_bar)*(weight-w_bar))/(sum((height-h_bar)^2))
beta_hat_0 = w_bar - (beta_hat_1*h_bar)
yhat = beta_hat_0 + height*beta_hat_1
e = (weight - yhat)^2
val = var(e)
n = length(mydata$height)
variance = sum((e)/(n-2))
print(variance)
```

2.

3.

4.
